from collections import namedtuple

from cyg_test.experiments.experiment_util import (BenchmarkCase,
                                                  UniformParallelArgs)

GPTModelConfig = namedtuple(
    "GPTModelConfig",
    ["seq_len", "hidden_size", "num_layers", "num_heads", "vocab_size"])
    
gpt_specs = {
    #                      Sï¼Œ   H,   L,  head,   V,
    "125M": GPTModelConfig(1024, 768, 12, 12, 51200),
    "350M": GPTModelConfig(1024, 1024, 24, 16, 51200),
    "760M": GPTModelConfig(1024, 1536, 24, 16, 51200),
    "760-1M": GPTModelConfig(32, 768, 12, 12, 51200),
    "760-2M": GPTModelConfig(48, 768, 12, 12, 51200),
    "760-3M": GPTModelConfig(64, 768, 12, 12, 51200),
    "760-4M": GPTModelConfig(128, 768, 12, 12, 51200),
    "1.3B": GPTModelConfig(1024, 2048, 24, 32, 51200),
    "2.6B": GPTModelConfig(1024, 2560, 32, 32, 51200),
    "6.7B": GPTModelConfig(1024, 4096, 32, 32, 51200),
    "15B": GPTModelConfig(1024, 5120, 48, 40, 51200),
    "39B": GPTModelConfig(1024, 8192, 48, 64, 51200),
    "76B": GPTModelConfig(1024, 10240, 60, 80, 51200),
}

force_dp_dict = {"force_batch_dim_to_mesh_dim": 0}
prefer_reduce_scatter=True
use_remat=False
max_global_batch_size = 1024

# B = batch_size, S = seq_len, H = hidden_size, L = num_layers, V = vocab_size
# head = num_heads,
# NB = num_micro_batches, PM = parallel_mode
# 3D config = 3D parallel config (Data, Operator, Pipeline)
# RS = prefer_reduce_scatter, Remat = use_rematerialization,
# FM = force_batch_dim_mapping,

# Temporary debug suite
# key = the number of gpus, value = a list of cases
# B, model, NB, PM, (RS, Remat, 3D Config, FM)
megatron_gpt_best_suite = {
    1: [
        BenchmarkCase(16, gpt_specs["760-1M"], 1, "uniform",
                      UniformParallelArgs(True, True, 1, 1, 1, True))
    ],
    2: [
        # 125M, DP, max_bs = 8 per gpu (whole model)
        BenchmarkCase(2, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(4, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(8, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(4, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(8, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(8, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(64, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(64, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(128, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(64, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(128, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        BenchmarkCase(259, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        
        # 125M, MP, max_bs = 8 per gpu (whole model)
        BenchmarkCase(1, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(2, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(4, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(8, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(2, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(4, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(8, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(4, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(8, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(64, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(8, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(64, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(128, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(16, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(32, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(64, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(128, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(256, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        
        # 125M, PP, max_bs = 8 per gpu (whole model)
        BenchmarkCase(1, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(2, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(4, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(8, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(16, gpt_specs["125M"], 1, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(2, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(4, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(8, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(16, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(32, gpt_specs["125M"], 2, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(4, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(8, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(16, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(32, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(64, gpt_specs["125M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(8, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(16, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(32, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(64, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(128, gpt_specs["125M"], 8, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(16, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(32, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(64, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(128, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(256, gpt_specs["125M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),

        # # 350M, DP, max_bs = 2 per gpu (whole model)
        # BenchmarkCase(2, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(4, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(4, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(8, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(8, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(16, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(16, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(32, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(32, gpt_specs["350M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        # BenchmarkCase(64, gpt_specs["350M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 2, 1, 1, True)),
        
        # # 350M, MP, max_bs = 2 per gpu (whole model)
        # BenchmarkCase(1, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(2, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(4, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(2, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(4, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(8, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(4, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(8, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(16, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(8, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(16, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(32, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        BenchmarkCase(16, gpt_specs["350M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(32, gpt_specs["350M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        # BenchmarkCase(64, gpt_specs["350M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 2, 1, True)),
        
        # # 350M, PP, max_bs = 4 per gpu (whole model)
        # BenchmarkCase(1, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(2, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(4, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(6, gpt_specs["350M"], 1, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(2, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(4, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(8, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(12, gpt_specs["350M"], 2, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(4, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(8, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(16, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(24, gpt_specs["350M"], 4, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(8, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(16, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(32, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(48, gpt_specs["350M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        BenchmarkCase(16, gpt_specs["350M"], 16, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(32, gpt_specs["350M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(64, gpt_specs["350M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
        # BenchmarkCase(96, gpt_specs["350M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, False)),
    ],
    8: [
        BenchmarkCase(128, GPTModelConfig(1024, 4096, 4, 32, 51200),
                      4, "uniform",
                      UniformParallelArgs(True, True, 4, 1, 2, True)),
    ],
}

megatron_gpt_search_suite = {
    1: [
        BenchmarkCase(16, gpt_specs["760-1M"], 1, "uniform",
                      UniformParallelArgs(True, True, 1, 1, 1, True))
    ],
    2: [
        BenchmarkCase(max_global_batch_size, gpt_specs["760-1M"], 4, "uniform",
                      UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
        # BenchmarkCase(max_global_batch_size, gpt_specs["760-1M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
        # BenchmarkCase(max_global_batch_size, gpt_specs["760-2M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
        # BenchmarkCase(max_global_batch_size, gpt_specs["760-3M"], 8, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
        # BenchmarkCase(max_global_batch_size, gpt_specs["760-1M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
        # BenchmarkCase(max_global_batch_size, gpt_specs["760-2M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
        # BenchmarkCase(max_global_batch_size, gpt_specs["760-3M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
        # BenchmarkCase(max_global_batch_size, gpt_specs["760-4M"], 16, "uniform",
        #               UniformParallelArgs(prefer_reduce_scatter, use_remat, 1, 1, 2, True)),
    ],
    8: [
        BenchmarkCase(128, GPTModelConfig(1024, 4096, 4, 32, 51200),
                      4, "uniform",
                      UniformParallelArgs(True, True, 4, 1, 2, True)),
    ],
}
